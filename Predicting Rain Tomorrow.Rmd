---
title: "Classification Modeling"
author: "Alex Navarro"
date: "10/29/2021"
output: html_document
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Load Packages and Data:
```{r setup, include =FALSE}
set.seed(1)
library(ROCR)
library(rpart)
library(rpart.plot)
library(lattice)
library(pROC)
library(naivebayes)
library(nnet)
library(NeuralNetTools)
library(caTools)
# Read data into system:
weather <- read.csv("weather.csv")
# check head 10 of data:
head(weather, n = 10)
# Check for NaN Values:
sum(is.na(weather))
# View Data Structure:
str(weather)
# Convert Rain Tomorrow to Factor:
weather$RainTomorrow <- as.factor(weather$RainTomorrow)
```
```{r, echo=FALSE}
# Split data into training/test set:
train=sample(17378,15000)
test=(c(1:17378)[-train])
weather_train <- weather[train,]
weather_test <- weather[test,]
```
# Modeling:
```{r, setup=FALSE}
# Forward Stepwise Regression:
# Specify a null model with no predictors:
null_model <- glm(RainTomorrow ~ 1, data = weather_train, family = binomial)
# Specify the full model using all of the potential predictors:
full_model <- glm(RainTomorrow ~ ., data = weather_train, family = binomial)
# Perform Forward Stepwise:
step_model <- step(null_model, scope = list(lower = null_model, upper = full_model), direction = "forward")
# Use a forward stepwise algorithm to build a parsimonious model:
```
```{r, setup=FALSE}
# Create Model Using best stepwise output:
step_model2 <- glm(RainTomorrow ~ Sunshine + Pressure3pm + AveHumidity + WindGustSpeed + 
    DifHumidity + Cloud3pm + WindSpeed3pm + Rainfall + WindDir3pm + 
    RainToday + MaxTemp + MinTemp + Temp3pm, family = "binomial",data = weather_train)
summary(step_model2)
```
# Model Diagnostics:
```{r, setup=FALSE}
# Plot the ROC of the stepwise model, tpr,fpr,fnr: and predict:
# Estimate the stepwise donation probability
step_prob <- predict(step_model2,newdata=weather_test,type = "response")
step_prob
```
```{r,setup=FALSE}
set.seed(1)
# Plot the ROC of the stepwise model
pred=ifelse(step_prob>.2,1,0)
table(pred,weather_test$RainTomorrow)
pre=prediction(step_prob,weather_test$RainTomorrow)
perf = performance(pre,"tpr","fpr")
plot(perf,auc.polygon=TRUE, main="ROC plot")
perf=performance(pre,"fpr","cutoff", col = c("blue"))
plot(perf,col = c("blue"))
perf=performance(pre,"fnr","cutoff")
plot(perf, col = c("green"))
prob=predict(step_model2,newdata=weather_train,type="response")
prob=predict(step_model2,newdata=weather,type="response")
pre=prediction(prob,weather$RainTomorrow)
perf=performance(pre,"tpr","rpp")
plot(perf, main="gain curve",print.cutoffs.at=c(.1,.2,.3,.4,.5))
abline(0,1)
# Calculate AUC:
#ROC <- roc(weather$RainTomorrow, prob)
#auc(ROC)
```
```{r, setup=FALSE}
#FPR_Variable <- 397(1420+397)
#FPR
#FNR = 109/(109+452)
#FNR
#Total = 1420+109+397+452
#Overall_Error_Rate = (397+109)/Total
#Overall_Error_Rate
```
# Decision Tree Classifier:
```{r, setup = FALSE}
set.seed(1)
library(rpart)
library(rpart.plot)
train=sample(17378,15000)
test=(c(1:17378)[-train])
weather_train <- weather[train,]
weather_test <- weather[test,]
# convert variables to factor:
weather$WindGustDir <- factor(weather$WindGustDir)
weather$WindDir3pm <- factor(weather$WindDir3pm)
# Create first Model:
m1 <- rpart(RainTomorrow~.,data=weather_train,method="class")
printcp(m1)
plotcp(m1)
rpart.plot(m1,type=3,extra=1)

# Produce the prune tree using the CP value 0.018465:
m2=prune(m1,cp=0.017337)
rpart.plot(m2,type=3,extra=1)
plotcp(m2, col = c("green"))
```
```{r, setup = FALSE}
set.seed(1)
prob <- predict(m2,newdata=weather_test,type = "prob")
prob
# Plot the ROC of the stepwise model
pred=ifelse(prob[,2]>.3,1,0)
table(pred,weather_test$RainTomorrow)
library(ROCR)
pre=prediction(prob[,2],weather_test$RainTomorrow)
perf = performance(pre,"tpr","fpr")
plot(perf,main="ROC plot")
perf=performance(pre,"fpr","cutoff", col = c("blue"))
plot(perf,col = c("blue"))
perf=performance(pre,"fnr","cutoff")
plot(perf, col = c("green"))
```
```{r,setup=FALSE}
fpr = 384/(1474+384)
False_Positive_Rate = fpr
False_Positive_Rate

fnr = 165/(165+355)
False_Negative_Rate = fnr
False_Negative_Rate

Overall_Error_Rate = (384+165)/2378
Overall_Error_Rate

Sensitivity = 1 - False_Negative_Rate
Sensitivity

Specificity = 1 - False_Positive_Rate
Sensitivity
```
# NaiveBayes Modeling:
```{r, setup = FALSE}
set.seed(1)
library(lattice)
# Split data into training/test set:
train=sample(17378,15000)
test=(c(1:17378)[-train])
weather_train <- weather[train,]
weather_test <- weather[test,]

# Change variables WindGustDir and WindDir3pm into factor variables with 2 levels:
weather$WindGustDir <- factor(weather$WindGustDir)
weather$WindDir3pm <- factor(weather$WindDir3pm)
weather$RainTomorrow <- factor(weather$RainTomorrow)

# Plots:
histogram(~MaxTemp|RainTomorrow,data = weather_train,layout=c(1,2), main = "Histogram of MaxTemp")
histogram(~Rainfall|RainTomorrow,data = weather_train,layout=c(1,2), main = "Histogram of Rainfall")
histogram(~Evaporation|RainTomorrow,data = weather_train,layout=c(1,2), main = "Histogram of Evaporation")
histogram(~Sunshine|RainTomorrow,data = weather_train,layout=c(1,2), main = "Histogram of Sunshine")
histogram(~WindGustSpeed|RainTomorrow,data = weather_train,layout=c(1,2), main = "Histogram of WindGustSpeed")
histogram(~WindSpeed3pm|RainTomorrow,data = weather_train,layout=c(1,2), main = "Histogram of WindSpeed3pm")
histogram(~Pressure3pm|RainTomorrow,data = weather_train,layout=c(1,2), main = "Histogram of Pressure3pm")
histogram(~Cloud3pm|RainTomorrow,data = weather_train,layout=c(1,2), main = "Histogram of Cloud3pm")
histogram(~Temp3pm|RainTomorrow,data = weather_train,layout=c(1,2), main = "Histogram of Temp3pm")
histogram(~AveHumidity|RainTomorrow,data = weather_train,layout=c(1,2), main = "Histogram of AveHumidity")
histogram(~DifHumidity|RainTomorrow,data = weather_train,layout=c(1,2), main = "Histogram of DifHumidity")

# Perform a test of independence for the categorical variables:
chisq.test(weather_train$RainTomorrow,weather_train$WindGustDir)
chisq.test(weather_train$RainTomorrow,weather_train$WindDir3pm)
chisq.test(weather_train$RainTomorrow,weather_train$RainToday)
# Create dataframe for choosen variables:
x.vars=c(5,7,11,13,15)
x=weather_train[,x.vars]
y=weather_train$RainTomorrow
# load naivebayes library:
library(naivebayes)
model=naive_bayes(x,y,usekernel=TRUE)
plot(model)
library(ROCR)
prob=predict(model,x,type='prob')
pred=prediction(prob[,2],y)
perf=performance(pred,"tpr","fpr")
plot(perf,main='ROC Plot')
perf=performance(pred,"fnr","cutoff")
plot(perf, col = c("green"))
perf=performance(pred,"fpr","cutoff")
plot(perf, col = c("purple"))
# Plot Gain Curve:
perf=performance(pre,"tpr","rpp")
plot(perf, main = "Gain Curve", print.cutoffs.at=c(.1,.2,.3,.4,.5))
abline(0,1)
# Compute and print the confusion matrix:
# Model is the name of the Naive Bayes estimated model and x is the input variables:
# y is th ename of the response variable and .3 is the cutoff value.
prob = predict(model, x, type = 'prob')
pred=ifelse(prob[,2]>.3,1,0)
table(pred,y)
# Modifications to compute and print the confusion matrix for the test data:
# Note that x and y need to be reset to the test data values.
x=weather_test[,x.vars]
y=weather_test$RainTomorrow
prob=predict(model,x,type="prob")
pred=ifelse(prob[,2]>.3,1,0)
table(pred,weather_test$RainTomorrow)
```
